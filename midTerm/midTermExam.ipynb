{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b012f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80fbc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data():\n",
    "     \n",
    "    return pd.read_csv(Path(\"housing.csv\"))\n",
    "\n",
    "def train_test_split(X, y, test_ratio = 0.2):\n",
    "    total_size = len(X)\n",
    "    print(total_size)\n",
    "\n",
    "    test_size = int(total_size * test_ratio)\n",
    "    train_size = total_size - test_size\n",
    "\n",
    "    np.random.seed(42)\n",
    "    rnd_indices = np.random.permutation(total_size)\n",
    "\n",
    "    X_train = X.iloc[rnd_indices[:train_size]]\n",
    "    y_train = y.iloc[rnd_indices[:train_size]]\n",
    "    X_test = X.iloc[rnd_indices[train_size:]]\n",
    "    y_test = y.iloc[rnd_indices[train_size:]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def fill_na(X, strategy = 'median'):\n",
    "    #X: ndarray array of shape (n_samples, n_features)\n",
    "    #return ndarray of shape (n_samples, n_features) with missing values filled by the strategy\n",
    "\n",
    "    imputer = SimpleImputer(strategy = strategy)\n",
    "    imputer.fit(X)\n",
    "\n",
    "    return imputer.transform(X)\n",
    "\n",
    "def get_outlier_indices(X):\n",
    "    #X: ndarray of shape (n_samples, n_features)\n",
    "    #y: label of shape (n_samples, k = 1)\n",
    "    #return the X and y with ourliers dropped\n",
    "    \n",
    "    isolation_forest = IsolationForest(random_state = 42)\n",
    "    outlier_pred = isolation_forest.fit_predict(X)\n",
    "\n",
    "    return outlier_pred\n",
    "\n",
    "def standard_scaler(X):\n",
    "    #scaling all columns in X such that for each column, we have mean = 0, std = 1\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    return std_scaler.fit_transform(X)\n",
    "\n",
    "def ordinal_encoder(df_one_column):\n",
    "    #df_one_column: a dataframe with one categorical column\n",
    "    #return an array of numbers representing categories \n",
    "    \n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    return ordinal_encoder.fit_transform(df_one_column)\n",
    "\n",
    "def one_hot_encoder(df_one_column):\n",
    "    #df_one_column: a dataframe with one categorical column\n",
    "    #return a 2d array of 0 / 1\n",
    "    \n",
    "    cat_encoder = OneHotEncoder(sparse = False)\n",
    "    return cat_encoder.fit_transform(df_one_column)\n",
    "\n",
    "\n",
    "def train(X_train, y_train):\n",
    "    \n",
    "    # defining parameter range \n",
    "    m = len(X_train)\n",
    "    \n",
    "    param_grid = {'alpha': [0.1/m, 1/m, 10/m, 100/m],  \n",
    "                  'eta0': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "                  'penalty':['l2'],\n",
    "                  'random_state': [42],\n",
    "                  'max_iter':[1000]}  \n",
    "\n",
    "    print(\"Training ...\")\n",
    "    grid = GridSearchCV(SGDRegressor(), param_grid, refit = True, verbose = 3,n_jobs=-1, cv = 3) \n",
    "\n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X_train, y_train) \n",
    "\n",
    "    # print best parameter after tuning \n",
    "    print(\"Training done\")\n",
    "    print(grid.best_params_)\n",
    "    return grid\n",
    "\n",
    "#    grid_predictions = grid.predict(X_test) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #sgd_reg = SGDRegressor() #(penalty=\"l2\", alpha=0.1 / m, tol=None, max_iter=1000, eta0=0.01, random_state=42)\n",
    "\n",
    "    #sgd_reg.fit(X, y.ravel()) # y.ravel() because fit() expects 1D targets\n",
    "    \n",
    "def main():\n",
    "\n",
    "    #1 load data\n",
    "    \n",
    "    housing = load_housing_data() # housing is a dataframe\n",
    "    \n",
    "    housing_X = housing.drop(\"median_house_value\", axis=1)\n",
    "    housing_y = housing[\"median_house_value\"].copy()    \n",
    "    \n",
    "    #2 split train, test sets\n",
    "    \n",
    "    housing_Xtrain, housing_Xtest, housing_ytrain, housing_ytest = train_test_split(housing_X, housing_y, test_ratio = 0.2)\n",
    "    \n",
    "    #3 prepare data for training\n",
    "    \n",
    "    #---handle missing values\n",
    "    \n",
    "    housing_Xtrain_num = housing_Xtrain.select_dtypes(include=[np.number])\n",
    "    housing_Xtest_num = housing_Xtest.select_dtypes(include=[np.number])\n",
    "    \n",
    "    housing_Xtrain_num_columns = housing_Xtrain_num.columns\n",
    "    \n",
    "    housing_Xtrain_num = fill_na(housing_Xtrain_num)\n",
    "    housing_Xtest_num = fill_na(housing_Xtest_num)\n",
    "    \n",
    "    #---drop outlier in training sets\n",
    "\n",
    "    outlier_indices = get_outlier_indices(housing_Xtrain_num)\n",
    "    housing_Xtrain = housing_Xtrain.iloc[outlier_indices == 1]\n",
    "    housing_ytrain = housing_ytrain.iloc[outlier_indices == 1]\n",
    "\n",
    "\n",
    "    housing_Xtrain_num = pd.DataFrame(housing_Xtrain_num, columns=housing_Xtrain_num_columns)\n",
    "    housing_Xtest_num = pd.DataFrame(housing_Xtest_num, columns=housing_Xtrain_num_columns)\n",
    "\n",
    "    housing_Xtrain_num = housing_Xtrain_num.iloc[outlier_indices == 1]\n",
    "\n",
    "    \n",
    "    \n",
    "    #---Scale\n",
    "    \n",
    "    housing_Xtrain_num = standard_scaler(housing_Xtrain_num)\n",
    "    housing_Xtest_num = standard_scaler(housing_Xtest_num)\n",
    "    \n",
    "    #---handle text column\n",
    "    \n",
    "    \n",
    "    \n",
    "    #4 train\n",
    "    \n",
    "    final_model = train(housing_Xtrain_num, housing_ytrain.values)\n",
    "    \n",
    "    #5 evaluate the final model\n",
    "    \n",
    "    final_predictions = final_model.predict(housing_Xtest_num)\n",
    "    final_rmse = mean_squared_error(housing_ytest, final_predictions, squared=False)\n",
    "    print(\"RMSE: \", final_rmse) # prints 41424.40026462184\n",
    "    \n",
    "    #plot train dev losses\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2b4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
